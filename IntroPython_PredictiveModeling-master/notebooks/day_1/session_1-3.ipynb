{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Session 1.3\n",
    "## Exploratory data analysis in Python\n",
    "\n",
    "- In the following session we are going to perform an **exploratory data analysis** of a data set\n",
    "- The goal is to gain a very basic understanding of the structure of the data set and some high-level understanding of the variables and their relationships\n",
    "- By the end of this notebook, we will be able to answer questions like\n",
    "    - What is the structure of the data set?\n",
    "    - What does the data set describe?\n",
    "    - What does the distribution of a variable look like?\n",
    "    - Are any of the variables related?\n",
    "- We will load the data set, examine its structure and contents at a high level, explore relationships between the variables in the data set, and ultimately create a correlation matrix for the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. First look at the data set\n",
    "- The very first step in any data analysis is to simply look at the file(s) containing the data\n",
    "- In many cases the file will be too large to open in a text editor; if this is the case, we could use Python or some other programming language to parse the first few hundred lines of the file to gain some idea of its structure\n",
    "- In this case, the file size is only ~123 kB; we can open it in a text editor\n",
    "- Using your favorite text editor (TextEdit, notepad, emacs, ...), open the file located at '../IntroPython_PredictiveModeling/notebooks/day_1/data/world_indexes/world_indexes_data'\n",
    "- Inspect the data for a couple minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that the file consists of numbers and words separated by commas---this indicates that the file is a 'comma separated value' or csv file\n",
    "- The first line in the file contains the column headers\n",
    "- Subsequent lines are the rows of data in the file\n",
    "- It looks like the first column is the name of a country, so each row presumably contains data for a different country\n",
    "- The column names describe various financial and health metrics for each country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the data set\n",
    "- Our cursory look at the data revealed that\n",
    "    - The file is only 123 kB; the entire file can easily be loaded into memory\n",
    "    - The data set is csv formatted\n",
    "    - The first row contains column information\n",
    "    - The first column gives a country name, but every other column contains pure numerical data\n",
    "- Given the above properties of the file, it makes sense to create a `numpy.ndarray` of the numerical data and two auxiliary lists containing the column and country information\n",
    "- We can load the data set using the Python csv module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Exercise: Loading the data set (10 minutes)</font>\n",
    "- Open the data file and create a csv reader object to read the file\n",
    "- Put all of the feature names (the first row of the file, except for 'Id') into a Python `list` object\n",
    "- Put the country names into another Python `list` object\n",
    "- Load all of the numerical data into a `numpy array`\n",
    "- The following is a code block responsible for loading the data set as described above, but contains some bugs that need to be fixed\n",
    "- Carefully read through the code line-by-line to understand what it is doing, and fix all of the lines that have a comment starting with 'FIX THIS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import csv \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the data file\n",
    "file_path =                                                   # FIX THIS: Insert correct file path\n",
    "with open(file_path) as file_handle:\n",
    "    file_reader = csv.reader(file_handle, delimiter =    )    # FIX THIS: Need to specify the delimiter.\n",
    "                                                \n",
    "    # Process the header (first row of file)\n",
    "    \n",
    "    features = next(file_reader)[1:]    # The first row of the file is the header; which contains the column names\n",
    "                                        # The columns are our features\n",
    "                                        # We do not include the 'Id' column since it is more like a label or identity\n",
    "                                        # (name of country) than a feature\n",
    "    \n",
    "    \n",
    "    \n",
    "    K =                                 # FIX THIS: It's useful to store a variable K that gives the\n",
    "                                        #           number of features in the data set\n",
    "                                    \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Process the body\n",
    "    \n",
    "    countries = []    # List that will hold the names of the countries in the data set\n",
    "\n",
    "    X = np.empty((0, K), dtype = float)             # We create an empty numpy array that we will\n",
    "                                                      # add all the row data to\n",
    "    \n",
    "    \n",
    "    # Read in each row\n",
    "    for row in file_reader:\n",
    "        \n",
    "        # Add the first element in the row to the countries list\n",
    "                                                 # FIX THIS: Add the country name to the countries list\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Add the rest of the rows to the data array\n",
    "        # FIX THIS: Need to append each new row to our data matrix X\n",
    "        #           We will use np.vstack(); the first argument is already provided;\n",
    "        #           You need to provide the second argument, which is the data from the row that we are interested in\n",
    "        #           Hint: It may be helpful to print(row), and run the code to see what data row contains\n",
    "        #           Hint: What type of object is row? In order to use it with np.vstack(), we have to \n",
    "        #                 first turn it into a numpy row vector\n",
    "        X = np.vstack((X, ))\n",
    "        \n",
    "        \n",
    "for feature in features:\n",
    "    print(feature)\n",
    "for country in countries:\n",
    "    print(country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Great, now we have the data loaded into three structures:\n",
    "\n",
    "\n",
    "1. A ** numpy array ** containing just the numerical rows and columns\n",
    "2. A ** list ** that contains the feature names\n",
    "3. Another ** list ** that contains the country names\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It would be really useful if we had a way of accessing data by country and by feature; \n",
    "- for instance, \n",
    "    - a question might be \"What is the mean 'Life expectancy at birth- years' of all the countries?\"\n",
    "    - or, determine Sweden's 'Population affected by natural disasters average annual per million people 2005-2014'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Exercise: Functions to return row/column given country/feature (5 minutes)</font>\n",
    "- Write a function `GetRowIndex()` to return the row of a given country from the data matrix X\n",
    "- Write a function `GetColumnIndex()` to return the column of a given feature name\n",
    "- If the name is invalid, raise an error with \n",
    "    - `raise ValueError([your own error message here])`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Insert solution here! #\n",
    "#########################\n",
    "\n",
    "def GetRowIndex(search_country):\n",
    "    for i, country in enumerate(countries):\n",
    "        # TODO 1: Complete the function!\n",
    "        \n",
    "    raise ValueError('Country not found:', search_country)\n",
    "    \n",
    "\n",
    "    \n",
    "def GetColumnIndex(search_feature):\n",
    "    # Complete the function!\n",
    "    \n",
    "    raise ValueError('Feature not found:', search_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Exercise: Practice accessing the data set (5 minutes)</font>\n",
    "- Now that we have extracted the data from its csv file and written our support functions to access it, we are prepared to actually work with the data set\n",
    "- For practice, calculate/extract the following:\n",
    "    - A list of the prison population for every country\n",
    "    - All of Australia's feature data\n",
    "    - Under five mortality rate for children for Sweden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Insert solution here! #\n",
    "#########################\n",
    "\n",
    "# Create a list containing the prison population of every country\n",
    "feature_name = 'Prison population per 100k people'\n",
    "\n",
    "prison_pop = 'TODO 1'\n",
    "\n",
    "for i in range(len(countries)):\n",
    "    print(countries[i], prison_pop[i])\n",
    "print('\\n\\n\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################\n",
    "# Insert solution here! #\n",
    "#########################\n",
    "\n",
    "# Create a list of Australia's features\n",
    "country_name = 'Australia'\n",
    "\n",
    "australia_features = 'TODO 2'\n",
    "\n",
    "\n",
    "for i in range(len(features)):\n",
    "    print(features[i], australia_features[i])\n",
    "print('\\n\\n\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################\n",
    "# Insert solution here! #\n",
    "#########################\n",
    "\n",
    "# Calculate Sweden's mortality rate for children under the age of 5\n",
    "country_name = 'Sweden'\n",
    "feature_name = 'Under-five Mortality 2013 thousands'\n",
    "\n",
    "\n",
    "sweden_underfivemortality = 'TODO 3'\n",
    "\n",
    "\n",
    "print(\"Sweden's under 5 mortality\", sweden_underfivemortality)\n",
    "print('\\n\\n\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-set specific questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Exercise: Finding the country with most homeless from natural disaster (5 minutes)</font>\n",
    "- Hints:\n",
    "    - Use `np.argsort()`, which will return the indices of the data set after it is sorted low-to-high\n",
    "    - Once you have the index of the highest value; figure out which country it belongs to using the `countries` list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Insert solution here! #\n",
    "#########################\n",
    "\n",
    "feature_name = 'Homeless people due to natural disaster 2005 2014 per million people'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Exercise: List the countries with the highest 3 and lowest 3 expected years of schooling and the countries with the highest 3 and lowest 3 Fossil fuels percentage of total(10 minutes) is there an overlap?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Insert solution here! #\n",
    "#########################\n",
    "feature_name_1 = 'Expected years of schooling'\n",
    "feature_name_2 = 'Fossil fuels percentage of total 2012'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots\n",
    "\n",
    "- Plotting is one of the most effective ways of gaining insight into a data set\n",
    "- Histograms reveal the distributions of individual features\n",
    "- Scatter plots can reveal relationships between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "x_feature_name = 'Human Development Index HDI-2014'\n",
    "y_feature_name = 'Adolescent birth rate 15-19 per 100k 20102015'\n",
    "\n",
    "x_index = GetColumnIndex(x_feature_name)\n",
    "y_index = GetColumnIndex(y_feature_name)\n",
    "\n",
    "x_data = X[:, x_index]\n",
    "y_data = X[:, y_index]\n",
    "\n",
    "# Make plot\n",
    "plt.scatter(x_data, y_data)\n",
    "\n",
    "plt.xlabel(x_feature_name)\n",
    "plt.ylabel(y_feature_name)\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Exercise: Plotting a histogram of Human Development Index (5 minutes)</font>\n",
    "    - Plot a histogram of the Human Development Index feature with 15 bins\n",
    "    - Be sure to label the axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Insert solution here! #\n",
    "#########################\n",
    "\n",
    "column_name = 'Human Development Index HDI-2014'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Exercise: Creating a scatterplot function (10 minutes)</font>\n",
    "- Create a function that takes in two column names and plots the data as a scatter plot\n",
    "- The function should include two optional arguments that allow the user to specify the x/y range--if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Insert solution here! #\n",
    "#########################\n",
    "\n",
    "def CreateScatterplot(feature_name_x, feature_name_y, xrange = None, yrange = None):\n",
    "    \n",
    "    # Get column indexes\n",
    "    \n",
    "    \n",
    "    # Get column data\n",
    "    \n",
    "    \n",
    "    # Make plot\n",
    "    \n",
    "    \n",
    "    # Label plot\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Exercise: Plotting prison population vs human development index (10 minutes)</font>\n",
    "- Create a scatter plot of 'Prison Population per 100k people' vs 'Human Development Index HDI-2014'\n",
    "- Are there any noticable outliers?\n",
    "    - If so, pick a couple outliers and determine which country they belong to\n",
    "        - Hints: \n",
    "            - Use the `np.where()` function to 'slice' out the elements in a column with a particular range\n",
    "            - For instance, you could use `np.where(GetColumn(feature_1) > 0.5)` to find all of the elements where the 'feature_1' column is greater than 0.5\n",
    "            - Use `np.where()` again for the other feature\n",
    "            - Look for mutual data points shared between the two np.where() results; this is the country within the specified bounds\n",
    "            - You can use the `np.intersect1d()` function to manually find the shared element\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Insert solution here! #\n",
    "#########################\n",
    "\n",
    "# Create scatter plot\n",
    "#####################\n",
    "\n",
    "\n",
    "\n",
    "# Get indexes of HDI and prison features\n",
    "########################################\n",
    "\n",
    "\n",
    "\n",
    "# Get the column data out\n",
    "#########################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Select the outliers (using np.where)\n",
    "######################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Exercise: Correlated and uncorrelated data(10 minutes)</font>\n",
    "- Create a scatter plot of 'Human Development Index...' vs 'Carbon dioxide emissions...'\n",
    "    - Does the relationship make sense to you? Why or why not?\n",
    "- Now create a scatter plot of 'Gender Inequality Index...' vs 'Forest area percentage of total land area 2012'\n",
    "    - How does this plot differ from the previous plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_column_name = 'Carbon dioxide emissions per capita 2011 Tones'\n",
    "y_column_name = 'Human Development Index HDI-2014'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_column_name = 'Gender Inequality Index 2014'\n",
    "y_column_name = 'Forest area percentage of total land area 2012'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Covariance and Correlation matrices\n",
    "- So far in our exploratory data analysis we've looked for relationships between variables manually by plotting their scatter plots\n",
    "- Correlation matrices are a means of quantifying relationships between pairs of variables\n",
    "\n",
    "- The covariance of two variables $X$ and $Y$ is given by\n",
    "$$ \n",
    "\\begin{align}\n",
    "        \\mathrm{cov}\\left(X,Y\\right)=\\Sigma_{XY}&=E\\left[\\left(X-\\mu_{X}\\right)\\left(Y-\\mu_{Y}\\right)\\right] \\\\\n",
    "        \\Sigma_{XY}&=\\frac{\\sum_{i}\\left(x_{i}-\\mu_{X}\\right)\\left(y_{i}-\\mu_{Y}\\right)}{N}\\\\\n",
    "        \\Sigma_{XY}&=\\frac{1}{N}\\left[\\left(x_{1}-\\mu_{X}\\right)\\left(y_{1}-\\mu_{Y}\\right)+\\left(x_{2}-\\mu_{X}\\right)\\left(y_{2}-\\mu_{Y}\\right)+...+\\left(x_{N}-\\mu_{X}\\right)\\left(y_{N}-\\mu_{Y}\\right)\\right],\n",
    "\\end{align}  \n",
    "$$\n",
    "\n",
    "where X is a vector of a feature across all $N$ samples $X=\\left(x_{1}, x_{1}, ..., x_{N}\\right)$ and $\\mu_{X}$ is the average of $X$.\n",
    "\n",
    "Notice that $\\Sigma_{XX}=E\\left[\\left(X-\\mu_{X}\\right)\\left(X-\\mu_{X}\\right)\\right]=E\\left[\\left(X-\\mu_{X}\\right)^{2}\\right]=\\sigma^{2}_{X}$---** the covariance of a vector with itself is its variance **\n",
    "\n",
    "The covariance can be positive, negative, or zero depending on three cases:\n",
    "\n",
    "- ** Positive **: If $x_{i}-\\mu_{X}$ is positive, then $y_{i}-\\mu_{Y}$ tends to be positive as well\n",
    "    - This means that when $x_{i}$ is above its average value, $y_{i}$ tends to be above its average value as well\n",
    "- ** Zero **: $x_{i}-\\mu_{x}$ and $y_{i}-\\mu_{y}$ change between positive and negative independent of each other; for some values, they are above average together, for others they are below average together\n",
    "- ** Negative **: $x_{i}$ tends to be above average when $y_{i}$ tends to be below average\n",
    "\n",
    "- Covariance gives us a means of quantifying a relationship between two variables\n",
    "\n",
    "\n",
    "- For $K$ variables we can calculate the covariance of all pairs and put it into a $K\\times K$ matrix $\\Sigma$\n",
    "\n",
    "\n",
    "### \\begin{bmatrix}\n",
    "    \\sigma_{X_{1}X_{1}} & \\Sigma_{X_{1}X_{2}} & \\Sigma_{X_{1}X_{3}} & \\dots & \\Sigma_{X_{1}X_{K}} \\\\\n",
    "    \\Sigma_{X_{2}X_{1}} & \\sigma_{X_{2}X_{2}} & \\Sigma_{X_{2}X_{3}} & \\dots & \\Sigma_{X_{2}X_{K}} \\\\\n",
    "    \\Sigma_{X_{3}X_{1}} & \\Sigma_{X_{3}X_{2}} & \\sigma_{X_{3}X_{3}} & \\dots & \\Sigma_{X_{3}X_{K}} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\Sigma_{X_{K}X_{1}} & \\Sigma_{X_{K}X_{2}} & \\Sigma_{X_{K}X_{3}} & \\dots & \\sigma_{X_{K}X_{K}} \\\\\n",
    "\\end{bmatrix}\n",
    "\n",
    "- The covariance matrix is nice, but difficult to interpret because it is not *scale invariant*---the relative magnitude of covariances between different variables is impossible to interpret; the only conclusion we can draw is about the sign of the covariance\n",
    "- It would be nice if we had a means of *standardizing* the covariances so that they were comparable\n",
    "- One way to *standardize* the covariance matrix is by dividing each element $\\Sigma_{X_{i}X_{j}}$ by $\\sqrt{\\sigma_{X_{i}}\\sigma_{X_{j}}}$, which will scale all $\\Sigma_{X_{i}X_{j}}$ to the range $\\{-1,1\\}$\n",
    "- Why? \n",
    "    - Covariance is maximized when both vectors are exactly equal, in which case the covariance $\\Sigma_{X_{i}X_{j}}$ and scaling factor $\\sqrt{\\sigma_{X_{i}}\\sigma_{X_{j}}}^{-1}$ are both equal to the standard deviation, and the term goes to 1\n",
    "    - Covariance is **minimized** when both vectors have equal magnitude but opposite direction, in which case the term goes to -1\n",
    "    - Therefore, all covariances rescaled by $\\left(\\sqrt{\\sigma_{X_{i}}\\sigma_{X_{j}}}\\right)^{-1}$ are in the range $\\{-1,1\\}$, enabling meaningful comparison between them\n",
    "    - The resulting matrix is known as the correlation matrix, and each of its elements is the **Pearson correlation coefficient** of two vectors\n",
    "    \n",
    " \n",
    "### \\begin{bmatrix}\n",
    "    1 & \\frac{\\Sigma_{X_{1}X_{2}}}{\\sqrt{\\sigma_{X_{1}}\\sigma_{X_{2}}}} & \\frac{\\Sigma_{X_{1}X_{3}}}{\\sqrt{\\sigma_{X_{1}}\\sigma_{X_{3}}}} & \\dots & \\frac{\\Sigma_{X_{1}X_{K}}}{\\sqrt{\\sigma_{X_{1}}\\sigma_{X_{K}}}} \\\\\n",
    "    \\frac{\\Sigma_{X_{2}X_{1}}}{\\sqrt{\\sigma_{X_{2}}\\sigma_{X_{1}}}} & 1 & \\frac{\\Sigma_{X_{2}X_{3}}}{\\sqrt{\\sigma_{X_{2}}\\sigma_{X_{3}}}} & \\dots & \\frac{\\Sigma_{X_{2}X_{K}}}{\\sqrt{\\sigma_{X_{2}}\\sigma_{X_{K}}}} \\\\\n",
    "    \\frac{\\Sigma_{X_{3}X_{1}}}{\\sqrt{\\sigma_{X_{3}}\\sigma_{X_{1}}}} & \\frac{\\Sigma_{X_{3}X_{2}}}{\\sqrt{\\sigma_{X_{3}}\\sigma_{X_{2}}}} & 1 & \\dots & \\frac{\\Sigma_{X_{3}X_{K}}}{\\sqrt{\\sigma_{X_{3}}\\sigma_{X_{K}}}} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\frac{\\Sigma_{X_{K}X_{1}}}{\\sqrt{\\sigma_{X_{K}}\\sigma_{X_{1}}}} & \\frac{\\Sigma_{X_{K}X_{2}}}{\\sqrt{\\sigma_{X_{K}}\\sigma_{X_{2}}}} & \\frac{\\Sigma_{X_{K}X_{3}}}{\\sqrt{\\sigma_{X_{K}}\\sigma_{X_{3}}}} & \\dots & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "    \n",
    "    \n",
    "- One easy way to calculate the correlation matrix is by **standardizing** your data set by subtracting the data for each feature by that feature's mean, and dividing by its standard deviation\n",
    "\n",
    "$$ X'=\\frac{\\left(X-\\mu_{X}\\right)}{\\sigma_{X}} $$\n",
    "\n",
    "- In this case, the correlation matrix of $X$ is simply the covariance matrix of $X'=X'^{T}X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Exercise: Standardize the numpy array and plot correlation matrix (10 minutes)</font>\n",
    "- Create a new numpy data array called X_std that has been standardized\n",
    "- Plot the correlation matrix using plt.imshow(); choose a meaningful colormap from one of the options on [this page](https://matplotlib.org/examples/color/colormaps_reference.html)\n",
    "    - Hint: colormap can be specified with plt.imshow(matrix_name, cmap = [insert cmap name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Insert solution here! #\n",
    "#########################\n",
    "\n",
    "# Standardize data (X_std)\n",
    "##########################\n",
    "\n",
    "\n",
    "# Compute the correlation matrix (using np.dot)\n",
    "###############################################\n",
    "\n",
    "# Display the matrix as a heatmap (plt.imshow)\n",
    "##############################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some caveats about correlation...\n",
    "![correlation pic](./images/correlation_dependence.png)\n",
    "\n",
    "- Correlation is useful to see if two variables are related\n",
    "- However, correlation is only a measure of ** linear ** dependence and doesn't yield much useful information about higher order relationships!\n",
    "- Nothing beats plotting all of the variables and looking at their relationship :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
